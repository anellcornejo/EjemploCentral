{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Elements of Statistical Learning\n",
    "\n",
    "Clasificaci贸n de puntos en un plano seg煤n dos posibles categorias, puntos rojos o azules\n",
    "\n",
    "Este notebook incluye todos los pasos tipicos de un ejercicio de Machine Learning, enfocandose en un problema de clasificacion entre dos categorias (rojo o azul) de los puntos de un plano. Todo esto en busqueda del grafico 2.4 del libro The Elements. Este notebook se dividir谩 en las siguientes partes:\n",
    "\n",
    "- Simulaci贸n de datos del train y del test\n",
    "    - En muchos ejercicios de Machine Learning estos datos son dados como condicion inicial, pero en nuestro caso nosotros los simulamos. Debemos recordar que una de las suposiciones de ML es que los datos siguen cierta funcion de probabilidad y que en principio conociendo esta funcion podriamos simularlos\n",
    "- Definicion de la funci贸n para calcular las predicciones o hacer la clasificacion (lineal,sigmoide, Knn, etc)\n",
    "    - En el lenguaje de ML esta funcion es llamada Hip贸tesis\n",
    "- Definicion de la funci贸n costo \n",
    "    -  En un primer caso usamos RSS como funcion de costo, pero en general podriamos considerar otras funciones de costo, dependiendo de las propiedades particulares de cada problema\n",
    "- Minimizaci贸n de la funci贸n costo para encontrar los par谩metros libres de la hip贸tesis \n",
    "    - En un primer caso encontramos los valores de los parametros theta de la funcion lineal minimizando analiticamente la funcion costo RSS, en lenguaje de ML esta ecuaci贸n es denominada Normal Equation. \n",
    "    - Sin embargo es necesario notar que tambi茅n existen otros metodos, que son numericos en general. Por ejemplo, anteriormente usamos la busqueda aleatoria de los paramteros seleccionando sistematicamente los valores que reducen RSS. Otro metodo, con nombre de hecho, es Gradient Descent que es el mas tipico de Machine Learning.\n",
    "- Visualizacion de las predicciones en el train y el test\n",
    "- Evaluacion cuantitativa de las predicciones en terminos de la accuracy y el test error\n",
    "    - Estos resultados nos permitiran escoger los mejores modelos para el problema planteado\n",
    "- Gr谩fico de la misclassification curves (Figure 2.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente importamos la librer铆a que utilizaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora importamos la librer铆a necesaria para la implementaci贸n de una red neuronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulaci贸n de datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado las indicaciones en la pagina 16 del libro \"The Elements of Statistical Learning\", se puede entender que el proceso de simulaci贸n del set de datos de entrenamiento es el siguiente.\n",
    "\n",
    "1- Primero se escoge el color a simular\n",
    "\n",
    "2- Dado el color, conocemos el centro y la matriz de covarianza de una gaussiana bivariada\n",
    "\n",
    "3- Con esta gaussiana bivariada generamos 10 centros. Esto lo hacemos solo una vez porque nos permite generar las observaciones asociadas a un set fijo de gaussianas bivariadas, 10 en nuestro caso. La idea de la simulaci贸n es generar observaciones que representen instancias asociados a un set de gaussianas bivariadas, no con respecto a una sola de ellas\n",
    "\n",
    "4- Con estos valores de los centros, mas una covarianza fija igual a la identidad/5, podemos asumir que conocemos los parametros de 10 gaussianas bivariadas\n",
    "\n",
    "5- Considerando estas 10 gaussianas bivariadas podemos generar nuestras observaciones\n",
    "\n",
    "6- Cada observacion se genera de la siguiente forma:\n",
    "\n",
    "    1- Se escoge uno de los centros dados anteriormente y su gaussiana bivariada correspondiente\n",
    "    2- Se genera un valor de la posicion siguiendo esta gaussiana bivariada   \n",
    "    3- Se vuelve a 6.1 y se repite el proceso, 100 veces por cada color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicion de los centros de las gaussianas bivariadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centros_asociados_a_cada_color(color, kcentros):\n",
    "   \n",
    "    centro = np.array([0,0])\n",
    "    covarianza = np.identity(2)\n",
    "    \n",
    "    if color == 0: #azul\n",
    "        centro = np.array([1,0])\n",
    "    \n",
    "    if color == 1: #rojo\n",
    "        centro = np.array([0,1])\n",
    "        \n",
    "    np.random.seed(15)   #esto fijar谩 la semilla del random para sistematizar la aleatoriedad.\n",
    "    lista_de_centros = np.random.multivariate_normal(centro,covarianza,kcentros).T\n",
    "        \n",
    "    return lista_de_centros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centros_azul = centros_asociados_a_cada_color(0,10)\n",
    "centros_rojo = centros_asociados_a_cada_color(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_colors(ptos_azul, ptos_rojo):\n",
    "\n",
    "    x1azul = ptos_azul[0]\n",
    "    x2azul = ptos_azul[1]\n",
    "    \n",
    "    x1rojo = ptos_rojo[0]\n",
    "    x2rojo = ptos_rojo[1]\n",
    "    \n",
    "    plt.plot(x1azul,x2azul,\"bo\")\n",
    "    plt.plot(x1rojo,x2rojo,\"ro\")\n",
    "    plt.axis([-4,4,-4,4])\n",
    "    plt.title(\"Distribucion de puntos segun el color\")\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(centros_azul, centros_rojo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacion de la funcion que simula los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simulacion(centros, N):\n",
    "    \n",
    "    Ncentros = centros.shape[1]\n",
    "    \n",
    "    #Inicializamos la lista de observaciones \n",
    "    observations = np.zeros((2,N))\n",
    "    \n",
    "    #Definimos un valor global para la covarianza\n",
    "    covarianza = np.identity(2)/5\n",
    "       \n",
    "    #hacemos un loop entre 0 y N para generar todos las observaciones requeridas\n",
    "    \n",
    "    for obs in range(0,N):\n",
    "        #generamos un numero aleatorio entre los n煤meros 0 y Ncentros-1 para escoger el centro de nuestra gaussiana bivariada\n",
    "        random.seed(obs**2)\n",
    "        indice_del_centro = random.randint(0, Ncentros-1)\n",
    "        \n",
    "        xcentro = centros[0,indice_del_centro]\n",
    "        ycentro = centros[1,indice_del_centro]\n",
    "        \n",
    "        mk_centro = np.array([xcentro, ycentro])\n",
    "        \n",
    "        np.random.seed(obs+10)\n",
    "        centro_aux = np.random.multivariate_normal(mk_centro,covarianza,1).T\n",
    "    \n",
    "        observations[0,obs] = centro_aux[0,0]\n",
    "        observations[1,obs] = centro_aux[1,0]\n",
    "    \n",
    "    return observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptos_observados_azul_train =  Simulacion(centros_azul, 100)\n",
    "ptos_observados_rojo_train =  Simulacion(centros_rojo, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(ptos_observados_azul_train, ptos_observados_rojo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos del  conjunto de testeo\n",
    "Se generar谩n 5000 puntos para cada color (en total ser谩n 10000 puntos) a partir de los mismos 20 centros usados para el conjunto de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptos_observados_azul_test =  Simulacion(centros_azul, 5000)\n",
    "ptos_observados_rojo_test =  Simulacion(centros_rojo, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(ptos_observados_azul_test, ptos_observados_rojo_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formaci贸n del Conjunto de Entrenamiento (SET_train) y del Conjunto de Testeo (SET_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET_train=[]\n",
    "\n",
    "x1azul_train = ptos_observados_azul_train[0,:]\n",
    "x2azul_train = ptos_observados_azul_train[1,:]\n",
    "\n",
    "x1rojo_train = ptos_observados_rojo_train[0,:]\n",
    "x2rojo_train = ptos_observados_rojo_train[1,:]\n",
    "\n",
    "# Se agregan estos puntos a SET_train con su correspondiente valor de Y. Si Y=0 corresponde a \n",
    "# la distribuci贸n normal azul. Si Y=1 corresponde a la distribuci贸n normal roja. Adicionalmente se agregar谩\n",
    "# el bias al inicio de cada fila en SET_train.\n",
    "\n",
    "for i in range(len(x1azul_train)): #Y=0\n",
    "    SET_train.append([1,x1azul_train[i],x2azul_train[i],0])\n",
    "\n",
    "for i in range(len(x1rojo_train)): #Y=1\n",
    "    SET_train.append([1,x1rojo_train[i],x2rojo_train[i],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET_test=[]\n",
    "\n",
    "x1azul_test = ptos_observados_azul_test[0,:]\n",
    "x2azul_test = ptos_observados_azul_test[1,:]\n",
    "\n",
    "x1rojo_test = ptos_observados_rojo_test[0,:]\n",
    "x2rojo_test = ptos_observados_rojo_test[1,:]\n",
    "\n",
    "for i in range(len(x1azul_test)): #Y=0\n",
    "    SET_test.append([1,x1azul_test[i],x2azul_test[i],0])\n",
    "\n",
    "for i in range(len(x1rojo_test)): #Y=1\n",
    "    SET_test.append([1,x1rojo_test[i],x2rojo_test[i],1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora reordenamos de manera aleatoria cada uno de los SETs para no perder generalidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(SET_train)\n",
    "np.random.shuffle(SET_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los largos correspondientes a cada SET se muestran a continuaci贸n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(SET_train), len(SET_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An谩lisis de funciones para calcular predicciones.\n",
    "\n",
    "## Caso 1: M铆nimos cuadrados\n",
    "\n",
    "- Hip贸tesis: funci贸n lineal\n",
    "- Funci贸n costo: RSS \n",
    "- Minimizaci贸n: theta obtenido te贸ricamente (Normal Equation)\n",
    "- Evaluaci贸n: accuracy y test error\n",
    "\n",
    "En este caso asumimos que el modelo de clasificaci贸n o hipotesis esta dado por una funcion lineal del tipo \n",
    "\n",
    "$$ h(x_1^{(i)},x_2^{(i)}) = \\theta_0 + \\theta_1 x_1^{(i)} + \\theta_2 x_2^{(i)} $$\n",
    "\n",
    "y que los valores de theta son obtenidos a partir de la busqueda del minimo de la funcion RSS con respecto a los datos del conjunto de entrenamiento. Este minimo puede ser encontrado analitcamente, como es nuestro caso actual, pero tambien puede ser encontrado numericamente, por ejemplo utilizando generacion de puntos aleatorios y seleccion del minimo. \n",
    "\n",
    "Forma anal铆tica:\n",
    "\n",
    "$$ RSS(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m (y^{(i)}\n",
    "- x^{(i)}\\theta)^2$$\n",
    "m indica el n煤mero de puntos, los que son de la forma $(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)})...,(x^{(m)},y^{(m)})$.\n",
    "Utilizando notaci贸n matricial, RSS() queda como:\n",
    "\n",
    "$$ RSS(\\theta) = \\frac{1}{2m}(Y - X\\theta)^T(Y - X\\theta)$$\n",
    "\n",
    "Cabe destacar que en este ejercicio en particular, $\\theta$ posee una dimensi贸n igual a 3, Y tiene una dimensi贸n igual a $N$ y X una dimensi贸n de $N x 3$.\n",
    "\n",
    "Finalmente, para encontrar los coeficientes que componen a vector $\\theta$ se debe derivar RSS() con respecto a $\\theta$ y luego igualar a 0, con lo que se obtiene lo siguiente.\n",
    "$$\\hat{\\theta} = (X^T X)^{-1}X^T Y$$\n",
    "\n",
    "Otra forma de hacer esta busqueda del minimo de RSS o funcion de costo en el lenguage de Machine Learning es utilizando una tecnica llamada Gradient Descent que es tipica en ML y que aparece explicado en el segundo item del curso Machine Learning de Andrew Ng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "Y_train=[]\n",
    "\n",
    "#Los valores de SET[i][1] y SET[i][2] se colocar谩n en X y se vizualizar谩n como las nuevas variables x1 y x2.\n",
    "for i in range(len(SET_train)):  \n",
    "    X_train.append([1,SET_train[i][1],SET_train[i][2]])\n",
    "\n",
    "\n",
    "#Ahora se colocar谩n los valores SET[i][3] en Y.\n",
    "for i in range(len(SET_train)): \n",
    "    Y_train.append(SET_train[i][3])\n",
    "    \n",
    "X_train=np.array(X_train)                     \n",
    "Y_train=np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "Y_test=[]\n",
    "\n",
    "for i in range(len(SET_test)):  \n",
    "    X_test.append([1,SET_test[i][1],SET_test[i][2]])\n",
    "\n",
    "\n",
    "#Ahora se colocar谩n los valores SET[i][3] en Y.\n",
    "for i in range(len(SET_test)): \n",
    "    Y_test.append(SET_test[i][3])\n",
    "    \n",
    "X_test=np.array(X_test)                     \n",
    "Y_test=np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape , Y_train.shape , Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT=X_train.transpose()\n",
    "XTdotX = np.dot(XT,X_train)\n",
    "XTdotX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTdotX_inversa = np.linalg.inv(XTdotX)\n",
    "XTdotX_inversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTdotX_inversa_dotXT = np.dot(XTdotX_inversa, XT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_analitico = np.dot(XTdotX_inversa_dotXT,Y_train)\n",
    "print(theta_analitico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Costo_lineal(theta,X,Y):    \n",
    "    m = len(X)\n",
    "    theta = np.array(theta)\n",
    "    Xtheta = np.dot(X, theta)\n",
    "    YXT =(Y-Xtheta).transpose()\n",
    "    YX = (Y-Xtheta)\n",
    "    RSS= 1/(2*m)*np.dot(YXT,YX) \n",
    "    return RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Costo_lineal(theta_analitico,X_train,Y_train)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizacion de las predicciones considerando los datos del conjunto de testeo y del conjunto de entrenamiento\n",
    "\n",
    "Con el valor del vector theta_analitico es posible visualizar como funciona este modelo de prediccion con la funci贸n lineal para los puntos del conjunto de entrenamuiento y del conjunto de testeo separadamente.\n",
    "\n",
    "Para esto, primero se necesita crear las siguientes funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion_lineal(x1, x2, theta): \n",
    "    \n",
    "    y_prediccion = theta[0] + x1*theta[1] + x2*theta[2]\n",
    "    return y_prediccion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listas_de_predicciones_lineal(SET):\n",
    "\n",
    "    lista_de_predicciones_azul = []\n",
    "    lista_de_predicciones_rojo = []\n",
    "\n",
    "    for pto in range(len(SET)):\n",
    "        prediccion = funcion_lineal(SET[pto][1], SET[pto][2], theta_analitico)\n",
    "\n",
    "    #Utilizando el valor de la prediccion separamos entre puntos azules y rojos\n",
    "    \n",
    "        if (prediccion <= 0.5):\n",
    "            lista_de_predicciones_azul.append([SET[pto][1], SET[pto][2]])\n",
    "        if (prediccion > 0.5):\n",
    "            lista_de_predicciones_rojo.append([SET[pto][1], SET[pto][2]])\n",
    "        \n",
    "    return np.array(lista_de_predicciones_azul), np.array(lista_de_predicciones_rojo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizar las predicciones hechas haremos lo siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_azul_train_lineal, prediccion_rojo_train_lineal = listas_de_predicciones_lineal(SET_train)\n",
    "\n",
    "prediccion_azul_train_lineal_t = prediccion_azul_train_lineal.transpose()\n",
    "prediccion_rojo_train_lineal_t = prediccion_rojo_train_lineal.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_azul_test_lineal, prediccion_rojo_test_lineal = listas_de_predicciones_lineal(SET_test)\n",
    "\n",
    "prediccion_azul_test_lineal_t = prediccion_azul_test_lineal.transpose()\n",
    "prediccion_rojo_test_lineal_t = prediccion_rojo_test_lineal.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto podemos comparar visualmente las predicciones sobre el conjunto de entrenamiento y el coonjunto de testeo. A continuaci贸n se observan los 200 puntos simulados inicialmente que pertenecen al conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(ptos_observados_azul_train, ptos_observados_rojo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci贸n se observa la predicci贸n hecha por la funci贸n lineal en el conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(prediccion_azul_train_lineal_t, prediccion_rojo_train_lineal_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci贸n observamos los 10000 puntos creados anteriormente que pertenecen al SET_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(ptos_observados_azul_test, ptos_observados_rojo_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci贸n se observa la predicci贸n hecha por la funci贸n lineal para estos puntos pertenecientes a SET_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(prediccion_azul_test_lineal_t, prediccion_rojo_test_lineal_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci贸n de la hipotesis lineal en terminos de las metricas \"Accuracy\" y el \"Test Error\"\n",
    "\n",
    "Por definicion vamos a considerar que la accuracy y el test error estan dados por\n",
    "\n",
    "$$Accuracy = \\frac{PC}{PC+ PI}$$ \n",
    "Con PC los puntos predichos correctamente y PI los puntos predichos incorrectamente\n",
    "\n",
    "$$Test_{error} = 1 - accuracy$$\n",
    "\n",
    "Estas son m茅tricas que nos permiten evaluar la performance de la hip贸tesis (en este caso la funci贸n lineal) una vez que hemos encontrado los valores de los parametros libres ($\\theta$). Evaluaremos estas dos m茅tricas en ambos conjuntos de datos (el de entrenamiento y el de testeo).\n",
    "\n",
    "El valor del Accuracy (o la exactitud) medido en el conjunto de entrenamiento nos indica cuantitativamente el nivel de aprendizaje del modelo, dado que en este paso estamos intentando ajustar el modelo a los datos conocidos. Mientras que el Acurracy medido en el conjunto de testeo nos indica su poder de prediccion, dado que estos datos no fueron utilizados para el entrenamiento del modelo. \n",
    "\n",
    "Normalmente se espera que el valor de la Accuracy sea mejor (o m谩s cercano a 1) en el conjunto de entrenamiento que en el conjunto de testeo, porque los datos del primer conjunto fueron los utilizados para calcular los parametros del modelo. Sin embargo esto no est谩 garantizado matem谩ticamente.\n",
    "\n",
    "En general es recomendable obtener un valor del accuracy cercano a 1 en el conjunto de testeo dado que nuestro objectivo final es tener poder de prediccion, no solo de ajustar los datos conocidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_funcion_lineal(SET, theta):\n",
    "\n",
    "    ptos_correctos = 0\n",
    "    ptos_incorrectos = 0\n",
    "    \n",
    "    for pto in range(len(SET)):\n",
    "        prediccion = funcion_lineal(SET[pto][1], SET[pto][2], theta)\n",
    "        \n",
    "        if (((prediccion < 0.5) and (SET[pto][3]==0)) or\n",
    "            ((prediccion > 0.5) and (SET[pto][3]==1))):\n",
    "            \n",
    "            ptos_correctos = ptos_correctos + 1\n",
    "        else:\n",
    "            ptos_incorrectos = ptos_incorrectos + 1\n",
    "            \n",
    "    ratio = ptos_correctos/(ptos_correctos + ptos_incorrectos)\n",
    "        \n",
    "        \n",
    "    print(\"puntos correctos: %d y puntos incorrectos: %d\"%(ptos_correctos, ptos_incorrectos))\n",
    "        \n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci贸n del modelo usando el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_lineal = accuracy_funcion_lineal(SET_train, theta_analitico)\n",
    "train_error_lineal = 1 - train_accuracy_lineal\n",
    "print(\"train accuracy lineal: %.2f and test error lineal: %.2f \"%(train_accuracy_lineal, train_error_lineal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci贸n del modelo usando el conjunto de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_lineal = accuracy_funcion_lineal(SET_test, theta_analitico)\n",
    "test_error_lineal = 1 - test_accuracy_lineal\n",
    "print(\"test accuracy lineal: %.2f and test error lineal: %.2f \"%(test_accuracy_lineal, test_error_lineal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso 2: Funci贸n Sigmoid\n",
    "\n",
    "- Hip贸tesis 2: Funci贸n sigmoid ($\\sigma$)\n",
    "- Funci贸n de costo: $J(\\theta)$ regresi贸n log铆stica \n",
    "- Minimizaci贸n: theta obtenido por gradient descent\n",
    "- Evaluaci贸n: accuracy y test error\n",
    "\n",
    "Para este caso asumimos que el modelo de clasificaci贸n o hipotesis esta dado por una funcion del tipo \n",
    "\n",
    "$$ h(x_1^{(i)},x_2^{(i)}) = \\sigma(\\theta_0 + \\theta_1 x_1^{(i)} + \\theta_2 x_2^{(i)})$$\n",
    "$$h(x_1^{(i)},x_2^{(i)}) = \\frac{1}{1+e^{-(\\theta_0 + \\theta_1 x_1^{(i)} + \\theta_2 x_2^{(i)})}}$$\n",
    "\n",
    "Los valores de $\\theta$ son obtenidos a partir de la busqueda del minimo de la funcion $J(\\theta)$ con respecto a los datos del conjunto de entrenamiento.\n",
    "\n",
    "$$ J(\\theta) = \\frac{-1}{m}\\sum_{i=1}^m (y^{(i)}\\log(h(x_1^{(i)},x_2^{(i)}))+(1-y^{(i)})\\log(1-h(x_1^{(i)},x_2^{(i)})))$$\n",
    "\n",
    "Este minimo puede ser encontrado anal铆ticamente, aleatoriamente o con gradient descent. En este caso utilizaremos el m茅todo de gradient descent. Este m茅todo es un algoritmo de optimizaci贸n que permite converger hacia el valor m铆nimo de la funci贸n de costo mediante un proceso iterativo.\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}$$\n",
    "\n",
    "En donde el s铆mbolo $\":=\"$ significa que lo que aparece al costado izquierdo de la ecuaci贸n se actualizar谩 en cada iteraci贸n con el valor obtenido en el costado derecho de esta. El 铆ndice de aprendizaje es representado por $\\alpha$, el cual indica el tama帽o de los pasos que se dar谩n en cada iteraci贸n y debe ser escogido estrat茅gicamente. La implementaci贸n de este algoritmo se puede vectorizar como se muestra a continuaci贸n.\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\frac{\\alpha}{m}X^T (g(X \\theta)-y)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_inicial = [] \n",
    "for i in range(len(theta_analitico)):\n",
    "    np.random.seed(10)\n",
    "    a = np.random.uniform(theta_analitico[i] - 0.5 , theta_analitico[i] + 0.5) \n",
    "    theta_inicial.append(a)\n",
    "\n",
    "print(theta_analitico, theta_inicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(v):\n",
    "    largo = len(v)\n",
    "    g=[]\n",
    "    \n",
    "    for i in range(largo):\n",
    "        g.append(1/(1+np.exp(-v[i])))\n",
    "    return np.array(g)\n",
    "\n",
    "\n",
    "\n",
    "def Costo_Sigmoid(X, y, theta):\n",
    "    Sum = 0\n",
    "    m = X.shape[0]\n",
    "    theta = np.array(theta)\n",
    "    \n",
    "    for i in range(m):\n",
    "        Xtheta = np.dot(X, theta)\n",
    "        Xtheta = np.array(Xtheta)\n",
    "        h = Sigmoid(Xtheta)\n",
    "        Sum = Sum + ((y[i]*np.log(h[i])) + (1 - y[i])*np.log(1 - h[i]))\n",
    "        \n",
    "    return -(Sum/m)\n",
    "\n",
    "\n",
    "\n",
    "def Gradient_Descent(theta,X,y,alpha, iteraciones):\n",
    "    X=np.array(X)\n",
    "    XT=X.transpose()\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    lista_J=[]\n",
    "    lista_iteracion = []\n",
    "    \n",
    "    for i in range(iteraciones):\n",
    "        \n",
    "        Xtheta = np.dot(X, theta)\n",
    "        resta = Sigmoid(Xtheta)-y\n",
    "        XTSigmoid = np.dot(XT,resta)\n",
    "        \n",
    "        theta = theta - (alpha/m) * XTSigmoid\n",
    "        \n",
    "        J = Costo_Sigmoid(X, y, theta) \n",
    "        \n",
    "        lista_J.append(J)\n",
    "        lista_iteracion.append(i)\n",
    "    \n",
    "    return np.array(lista_J) , np.array(lista_iteracion),theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos con valores de $\\alpha$ chicos y 50 iteraciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_1,iteraciones_1,theta_1 = Gradient_Descent(theta_inicial,X_train,Y_train,0.01,50)\n",
    "J_2,iteraciones_2,theta_2 = Gradient_Descent(theta_inicial,X_train,Y_train,0.1,50)\n",
    "J_3,iteraciones_3,theta_3 = Gradient_Descent(theta_inicial,X_train,Y_train,1,50)\n",
    "J_4,iteraciones_4,theta_4 = Gradient_Descent(theta_inicial,X_train,Y_train,5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iteraciones_1,J_1,\"ro\", label=\"alpha=0.01\")\n",
    "plt.plot(iteraciones_2,J_2,\"bo\",label=\"alpha=0.1\")\n",
    "plt.plot(iteraciones_3,J_3,\"co\",label=\"alpha=1\")\n",
    "plt.plot(iteraciones_4,J_4,\"yo\",label=\"alpha=5\")\n",
    "\n",
    "plt.title(\"Evoluci贸n funci贸n de costo\")\n",
    "plt.legend(loc='center right')\n",
    "plt.ylabel(\"Costo\")\n",
    "plt.xlabel(\"Iteraciones\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que con  =1  la funci贸n de costo pudo converger r谩pidamente a un valor estable y cercano al m铆nimo. Con 50 iteraciones y con  =1 , la funci贸n de costo vale 0.4174683. Ahora veamos que sucede con valores de $\\alpha$ m谩s grandes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_5,iteraciones_5,theta_5 = Gradient_Descent(theta_inicial,X_train,Y_train,5,20)\n",
    "J_6,iteraciones_6,theta_6 = Gradient_Descent(theta_inicial,X_train,Y_train,10,20)\n",
    "J_7,iteraciones_7,theta_7 = Gradient_Descent(theta_inicial,X_train,Y_train,15,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iteraciones_5,J_5,\"yo\", label=\"alpha=5\")\n",
    "plt.plot(iteraciones_6,J_6,\"go\",label=\"alpha=10\")\n",
    "plt.plot(iteraciones_7,J_7,\"mo\",label=\"alpha=15\")\n",
    "plt.legend(loc='center right')\n",
    "plt.title(\"Evoluci贸n funci贸n de costo\")\n",
    "plt.ylabel(\"Costo\")\n",
    "plt.xlabel(\"Iteraciones\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver este notebook me quedar茅 con $\\alpha = 7$ y con 20 iteraciones, ya que con estas variables la funci贸n de costo presenta un comportamiento estable y un valor muy peque帽o. Con 20 iteraciones y con $\\alpha=7$, el menor valor de la funci贸n de costo es 0.33182636 y el theta correspondiente se muestra a continuaci贸n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_4[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listas_de_predicciones_sigmoid(SET,theta):\n",
    "\n",
    "    lista_predicciones_azul = []\n",
    "    lista_predicciones_rojo = []\n",
    "    \n",
    "    X = []\n",
    "    for i in range(len(SET)):  \n",
    "        X.append([1,SET[i][1],SET[i][2]])\n",
    "    \n",
    "    Xtheta = np.dot(X,theta)\n",
    "    \n",
    "    prediccion = Sigmoid(Xtheta)\n",
    "    \n",
    "    for pto in range(len(SET)):\n",
    "    \n",
    "        if (prediccion[pto] <= 0.5):\n",
    "            lista_predicciones_azul.append([SET[pto][1], SET[pto][2]])\n",
    "        if (prediccion[pto] > 0.5):\n",
    "            lista_predicciones_rojo.append([SET[pto][1], SET[pto][2]])\n",
    "        \n",
    "    return np.array(lista_predicciones_azul), np.array(lista_predicciones_rojo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizaci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_azul_train_sigmoid, prediccion_rojo_train_sigmoid = listas_de_predicciones_sigmoid(SET_train,theta_4)\n",
    "\n",
    "prediccion_azul_train_sigmoid_t = prediccion_azul_train_sigmoid.transpose()\n",
    "prediccion_rojo_train_sigmoid_t = prediccion_rojo_train_sigmoid.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_azul_test_sigmoid, prediccion_rojo_test_sigmoid = listas_de_predicciones_sigmoid(SET_test,theta_4)\n",
    "\n",
    "prediccion_azul_test_sigmoid_t = prediccion_azul_test_sigmoid.transpose()\n",
    "prediccion_rojo_test_sigmoid_t = prediccion_rojo_test_sigmoid.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto podemos comparar visualmente las predicciones sobre el conjunto de entrenamiento y el conjunto de testeo, utilizando un modelo predictivo con la funci贸n sigmoid. A continuaci贸n se observan los 200 puntos simulados inicialmente que pertenecen al conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(ptos_observados_azul_train, ptos_observados_rojo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci贸n se observa la predicci贸n hecha por la funci贸n sigmoid en el conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(prediccion_azul_train_sigmoid_t, prediccion_rojo_train_sigmoid_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci贸n observamos los 10000 puntos creados anteriormente que pertenecen al SET_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(ptos_observados_azul_test, ptos_observados_rojo_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci贸n se observa la predicci贸n hecha por la funci贸n sigmoid para estos puntos pertenecientes a SET_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(prediccion_azul_test_sigmoid_t, prediccion_rojo_test_sigmoid_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci贸n de la hipotesis sigmoid en terminos de las metricas \"Accuracy\" y el \"Test Error\"\n",
    "\n",
    "Recordemos que:\n",
    "\n",
    "$$Accuracy = \\frac{PC}{PC+ PI}$$ \n",
    "Con PC los puntos predichos correctamente y PI los puntos predichos incorrectamente\n",
    "\n",
    "$$Test_{error} = 1 - accuracy$$\n",
    "\n",
    "Con estas m茅tricas evaluaremos la performance de la hip贸tesis de la funci贸n sigmoid. Evaluaremos estas dos m茅tricas en ambos conjuntos de datos (el de entrenamiento y el de testeo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_funcion_sigmoid(SET, theta):\n",
    "\n",
    "    ptos_correctos = 0\n",
    "    ptos_incorrectos = 0\n",
    "    \n",
    "    X = []\n",
    "    for i in range(len(SET)):  \n",
    "        X.append([1,SET[i][1],SET[i][2]])\n",
    "    \n",
    "    Xtheta = np.dot(X,theta)\n",
    "    \n",
    "    prediccion = Sigmoid(Xtheta)\n",
    "    \n",
    "    for pto in range(len(SET)):\n",
    "        \n",
    "        if (((prediccion[pto] <= 0.5) and (SET[pto][3]==0)) or\n",
    "            ((prediccion[pto] > 0.5) and (SET[pto][3]==1))):\n",
    "            \n",
    "            ptos_correctos = ptos_correctos + 1\n",
    "        else:\n",
    "            ptos_incorrectos = ptos_incorrectos + 1\n",
    "            \n",
    "    ratio = ptos_correctos/(ptos_correctos + ptos_incorrectos)\n",
    "        \n",
    "        \n",
    "    print(\"puntos correctos: %d y puntos incorrectos: %d\"%(ptos_correctos, ptos_incorrectos))\n",
    "        \n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci贸n del modelo usando el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_sigmoid = accuracy_funcion_sigmoid(SET_train, theta_4)\n",
    "train_error_sigmoid = 1 - train_accuracy_sigmoid\n",
    "print(\"train accuracy sigmoid: %.2f and test error sigmoid: %.2f \"%(train_accuracy_sigmoid, train_error_sigmoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci贸n del modelo usando el conjunto de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_sigmoid = accuracy_funcion_sigmoid(SET_test, theta_4)\n",
    "test_error_sigmoid = 1 - test_accuracy_sigmoid\n",
    "print(\"test accuracy sigmoid: %.2f and test error sigmoid: %.2f \"%(test_accuracy_sigmoid, test_error_sigmoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso 3: Redes Neuronales\n",
    "\n",
    "- Hip贸tesis: Funci贸n sigmoid ($\\sigma$)\n",
    "- Funci贸n de costo: binary_crossentropy\n",
    "- Minimizaci贸n: backpropagation\n",
    "- Evaluaci贸n: accuracy \n",
    "\n",
    "A帽adiremos una capa a la vez, las que seguir谩n las siguientes caracter铆sticas:\n",
    "\n",
    "El modelo esperar谩 filas de los datos con 2 variables, por lo que el argumento input_dim=2.\n",
    "La primera capa oculta tendr谩 2 nodos o neuronas (al parecer el bias no se considera), lo que obtenemos al escribir un 2 en la primera variable de entrada de Dense y tendr谩 una funci贸n de activaci贸n sigmoid, ya que de esta forma lo resolvimos en el resumen.\n",
    "La capa de salida tendr谩 solo una neurona y tambi茅n usar谩 una funci贸n de activaci贸n sigmoid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definici贸n del modelo utilizando Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=2, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilaci贸n del modelo:\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualizaci贸n de la red neuronal\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustar el modelo al conjunto de datos de entrenamiento (con esto se aprenden los wights)\n",
    "#no debemos considerar el bias, por eso ponemos X_train[:,1:]\n",
    "\n",
    "model.fit(X_train[:,1:], Y_train, epochs=150, batch_size=50)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluaci贸n del modelo usando el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_train, accuracy_train = model.evaluate(X_train[:,1:], Y_train)\n",
    "print('Accuracy train: %.2f' % (accuracy_train*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluaci贸n del modelo usando el conjunto de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluaci贸n del modelo para el conjunto de testeo\n",
    "J_test, accuracy_test = model.evaluate(X_test[:,1:], Y_test)\n",
    "print('Accuracy test: %.2f' % (accuracy_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_train = model.predict(X_train[:,1:]) #sin aproximar\n",
    "prediccion_final_train = [round(x[0]) for x in prediccion_train] #aproxima a 1 o a 0\n",
    "\n",
    "\n",
    "prediccion_test = model.predict(X_test[:,1:]) #sin aproximar\n",
    "prediccion_final_test = [round(x[0]) for x in prediccion_test] #aproxima a 1 o a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puntos_azul_train = []\n",
    "puntos_rojo_train = []\n",
    "\n",
    "for i in range(len(prediccion_final_train)):\n",
    "    if prediccion_final_train[i] == 1:\n",
    "        puntos_rojo_train.append(X_train[i,1:])\n",
    "    else:\n",
    "        puntos_azul_train.append(X_train[i,1:])\n",
    "        \n",
    "puntos_azul_test = []\n",
    "puntos_rojo_test = []\n",
    "\n",
    "for i in range(len(prediccion_final_test)):\n",
    "    if prediccion_final_test[i] == 1:\n",
    "        puntos_rojo_test.append(X_test[i,1:])\n",
    "    else:\n",
    "        puntos_azul_test.append(X_test[i,1:])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puntos_azul_train_t = np.array(puntos_azul_train).transpose()\n",
    "puntos_rojo_train_t = np.array(puntos_rojo_train).transpose()\n",
    "\n",
    "puntos_azul_test_t = np.array(puntos_azul_test).transpose()\n",
    "puntos_rojo_test_t = np.array(puntos_rojo_test).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_colors(ptos_azul, ptos_rojo):\n",
    "\n",
    "    x1azul = ptos_azul[0]\n",
    "    x2azul = ptos_azul[1]\n",
    "    \n",
    "    x1rojo = ptos_rojo[0]\n",
    "    x2rojo = ptos_rojo[1]\n",
    "    \n",
    "    plt.plot(x1azul,x2azul,\"bo\")\n",
    "    plt.plot(x1rojo,x2rojo,\"ro\")\n",
    "    plt.axis([-4,4,-4,4])\n",
    "    plt.title(\"Distribucion de puntos segun el color\")\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(puntos_azul_train_t, puntos_rojo_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(puntos_azul_test_t, puntos_rojo_test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando el valor del Acurracy obtenido para los tres modelos analizados, podemos notar que estos presentan un valor de Acurracy bastante similar. Esto muestra la consistencia del m茅todo gradient descent para encontrar los par谩metros libres de J($\\theta$), ya que obtuvo el mismo error que se calcul贸 anteriormente de manera anal铆tica para la hip贸tesis lineal. Para aumentar la presici贸n de la red neuronal se podr铆an utilizar m谩s neuronas en la capa oculta o agregar m谩s capas ocultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
