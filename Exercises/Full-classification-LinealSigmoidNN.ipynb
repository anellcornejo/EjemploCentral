{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Elements of Statistical Learning\n",
    "\n",
    "Clasificación de puntos en un plano según dos posibles categorias, puntos rojos o azules\n",
    "\n",
    "Este notebook incluye todos los pasos tipicos de un ejercicio de Machine Learning, enfocandose en un problema de clasificacion entre dos categorias (rojo o azul) de los puntos de un plano. Todo esto en busqueda del grafico 2.4 del libro The Elements. Este notebook se dividirá en las siguientes partes:\n",
    "\n",
    "- Simulación de datos del train y del test\n",
    "    - En muchos ejercicios de Machine Learning estos datos son dados como condicion inicial, pero en nuestro caso nosotros los simulamos. Debemos recordar que una de las suposiciones de ML es que los datos siguen cierta funcion de probabilidad y que en principio conociendo esta funcion podriamos simularlos\n",
    "- Definicion de la función para calcular las predicciones o hacer la clasificacion (lineal,sigmoide, Knn, etc)\n",
    "    - En el lenguaje de ML esta funcion es llamada Hipótesis\n",
    "- Definicion de la función costo \n",
    "    -  En un primer caso usamos RSS como funcion de costo, pero en general podriamos considerar otras funciones de costo, dependiendo de las propiedades particulares de cada problema\n",
    "- Minimización de la función costo para encontrar los parámetros libres de la hipótesis \n",
    "    - En un primer caso encontramos los valores de los parametros theta de la funcion lineal minimizando analiticamente la funcion costo RSS, en lenguaje de ML esta ecuación es denominada Normal Equation. \n",
    "    - Sin embargo es necesario notar que también existen otros metodos, que son numericos en general. Por ejemplo, anteriormente usamos la busqueda aleatoria de los paramteros seleccionando sistematicamente los valores que reducen RSS. Otro metodo, con nombre de hecho, es Gradient Descent que es el mas tipico de Machine Learning.\n",
    "- Visualizacion de las predicciones en el train y el test\n",
    "- Evaluacion cuantitativa de las predicciones en terminos de la accuracy y el test error\n",
    "    - Estos resultados nos permitiran escoger los mejores modelos para el problema planteado\n",
    "- Gráfico de la misclassification curves (Figure 2.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente importamos la librería que utilizaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora importamos la librería necesaria para la implementación de una red neuronal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulación de datos:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado las indicaciones en la pagina 16 del libro \"The Elements of Statistical Learning\", se puede entender que el proceso de simulación del set de datos de entrenamiento es el siguiente.\n",
    "\n",
    "1- Primero se escoge el color a simular\n",
    "\n",
    "2- Dado el color, conocemos el centro y la matriz de covarianza de una gaussiana bivariada\n",
    "\n",
    "3- Con esta gaussiana bivariada generamos 10 centros. Esto lo hacemos solo una vez porque nos permite generar las observaciones asociadas a un set fijo de gaussianas bivariadas, 10 en nuestro caso. La idea de la simulación es generar observaciones que representen instancias asociados a un set de gaussianas bivariadas, no con respecto a una sola de ellas\n",
    "\n",
    "4- Con estos valores de los centros, mas una covarianza fija igual a la identidad/5, podemos asumir que conocemos los parametros de 10 gaussianas bivariadas\n",
    "\n",
    "5- Considerando estas 10 gaussianas bivariadas podemos generar nuestras observaciones\n",
    "\n",
    "6- Cada observacion se genera de la siguiente forma:\n",
    "\n",
    "    1- Se escoge uno de los centros dados anteriormente y su gaussiana bivariada correspondiente\n",
    "    2- Se genera un valor de la posicion siguiendo esta gaussiana bivariada   \n",
    "    3- Se vuelve a 6.1 y se repite el proceso, 100 veces por cada color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definicion de los centros de las gaussianas bivariadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def centros_asociados_a_cada_color(color, kcentros):\n",
    "   \n",
    "    centro = np.array([0,0])\n",
    "    covarianza = np.identity(2)\n",
    "    \n",
    "    if color == 0: #azul\n",
    "        centro = np.array([1,0])\n",
    "    \n",
    "    if color == 1: #rojo\n",
    "        centro = np.array([0,1])\n",
    "        \n",
    "    np.random.seed(15)   #esto fijará la semilla del random para sistematizar la aleatoriedad.\n",
    "    lista_de_centros = np.random.multivariate_normal(centro,covarianza,kcentros).T\n",
    "        \n",
    "    return lista_de_centros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centros_azul = centros_asociados_a_cada_color(0,10)\n",
    "centros_rojo = centros_asociados_a_cada_color(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_colors(ptos_azul, ptos_rojo):\n",
    "\n",
    "    x1azul = ptos_azul[0]\n",
    "    x2azul = ptos_azul[1]\n",
    "    \n",
    "    x1rojo = ptos_rojo[0]\n",
    "    x2rojo = ptos_rojo[1]\n",
    "    \n",
    "    plt.plot(x1azul,x2azul,\"bo\")\n",
    "    plt.plot(x1rojo,x2rojo,\"ro\")\n",
    "    plt.axis([-4,4,-4,4])\n",
    "    plt.title(\"Distribucion de puntos segun el color\")\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(centros_azul, centros_rojo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementacion de la funcion que simula los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Simulacion(centros, N):\n",
    "    \n",
    "    Ncentros = centros.shape[1]\n",
    "    \n",
    "    #Inicializamos la lista de observaciones \n",
    "    observations = np.zeros((2,N))\n",
    "    \n",
    "    #Definimos un valor global para la covarianza\n",
    "    covarianza = np.identity(2)/5\n",
    "       \n",
    "    #hacemos un loop entre 0 y N para generar todos las observaciones requeridas\n",
    "    \n",
    "    for obs in range(0,N):\n",
    "        #generamos un numero aleatorio entre los números 0 y Ncentros-1 para escoger el centro de nuestra gaussiana bivariada\n",
    "        random.seed(obs**2)\n",
    "        indice_del_centro = random.randint(0, Ncentros-1)\n",
    "        \n",
    "        xcentro = centros[0,indice_del_centro]\n",
    "        ycentro = centros[1,indice_del_centro]\n",
    "        \n",
    "        mk_centro = np.array([xcentro, ycentro])\n",
    "        \n",
    "        np.random.seed(obs+10)\n",
    "        centro_aux = np.random.multivariate_normal(mk_centro,covarianza,1).T\n",
    "    \n",
    "        observations[0,obs] = centro_aux[0,0]\n",
    "        observations[1,obs] = centro_aux[1,0]\n",
    "    \n",
    "    return observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos del conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptos_observados_azul_train =  Simulacion(centros_azul, 100)\n",
    "ptos_observados_rojo_train =  Simulacion(centros_rojo, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(ptos_observados_azul_train, ptos_observados_rojo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos del  conjunto de testeo\n",
    "Se generarán 5000 puntos para cada color (en total serán 10000 puntos) a partir de los mismos 20 centros usados para el conjunto de entrenamiento. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ptos_observados_azul_test =  Simulacion(centros_azul, 5000)\n",
    "ptos_observados_rojo_test =  Simulacion(centros_rojo, 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(ptos_observados_azul_test, ptos_observados_rojo_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formación del Conjunto de Entrenamiento (SET_train) y del Conjunto de Testeo (SET_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET_train=[]\n",
    "\n",
    "x1azul_train = ptos_observados_azul_train[0,:]\n",
    "x2azul_train = ptos_observados_azul_train[1,:]\n",
    "\n",
    "x1rojo_train = ptos_observados_rojo_train[0,:]\n",
    "x2rojo_train = ptos_observados_rojo_train[1,:]\n",
    "\n",
    "# Se agregan estos puntos a SET_train con su correspondiente valor de Y. Si Y=0 corresponde a \n",
    "# la distribución normal azul. Si Y=1 corresponde a la distribución normal roja. Adicionalmente se agregará\n",
    "# el bias al inicio de cada fila en SET_train.\n",
    "\n",
    "for i in range(len(x1azul_train)): #Y=0\n",
    "    SET_train.append([1,x1azul_train[i],x2azul_train[i],0])\n",
    "\n",
    "for i in range(len(x1rojo_train)): #Y=1\n",
    "    SET_train.append([1,x1rojo_train[i],x2rojo_train[i],1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SET_test=[]\n",
    "\n",
    "x1azul_test = ptos_observados_azul_test[0,:]\n",
    "x2azul_test = ptos_observados_azul_test[1,:]\n",
    "\n",
    "x1rojo_test = ptos_observados_rojo_test[0,:]\n",
    "x2rojo_test = ptos_observados_rojo_test[1,:]\n",
    "\n",
    "for i in range(len(x1azul_test)): #Y=0\n",
    "    SET_test.append([1,x1azul_test[i],x2azul_test[i],0])\n",
    "\n",
    "for i in range(len(x1rojo_test)): #Y=1\n",
    "    SET_test.append([1,x1rojo_test[i],x2rojo_test[i],1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora reordenamos de manera aleatoria cada uno de los SETs para no perder generalidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(SET_train)\n",
    "np.random.shuffle(SET_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los largos correspondientes a cada SET se muestran a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(SET_train), len(SET_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de funciones para calcular predicciones.\n",
    "\n",
    "## Caso 1: Mínimos cuadrados\n",
    "\n",
    "- Hipótesis: función lineal\n",
    "- Función costo: RSS \n",
    "- Minimización: theta obtenido teóricamente (Normal Equation)\n",
    "- Evaluación: accuracy y test error\n",
    "\n",
    "En este caso asumimos que el modelo de clasificación o hipotesis esta dado por una funcion lineal del tipo \n",
    "\n",
    "$$ h(x_1^{(i)},x_2^{(i)}) = \\theta_0 + \\theta_1 x_1^{(i)} + \\theta_2 x_2^{(i)} $$\n",
    "\n",
    "y que los valores de theta son obtenidos a partir de la busqueda del minimo de la funcion RSS con respecto a los datos del conjunto de entrenamiento. Este minimo puede ser encontrado analitcamente, como es nuestro caso actual, pero tambien puede ser encontrado numericamente, por ejemplo utilizando generacion de puntos aleatorios y seleccion del minimo. \n",
    "\n",
    "Forma analítica:\n",
    "\n",
    "$$ RSS(\\theta) = \\frac{1}{2m} \\sum_{i=1}^m (y^{(i)}\n",
    "- x^{(i)}\\theta)^2$$\n",
    "m indica el número de puntos, los que son de la forma $(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)})...,(x^{(m)},y^{(m)})$.\n",
    "Utilizando notación matricial, RSS() queda como:\n",
    "\n",
    "$$ RSS(\\theta) = \\frac{1}{2m}(Y - X\\theta)^T(Y - X\\theta)$$\n",
    "\n",
    "Cabe destacar que en este ejercicio en particular, $\\theta$ posee una dimensión igual a 3, Y tiene una dimensión igual a $N$ y X una dimensión de $N x 3$.\n",
    "\n",
    "Finalmente, para encontrar los coeficientes que componen a vector $\\theta$ se debe derivar RSS() con respecto a $\\theta$ y luego igualar a 0, con lo que se obtiene lo siguiente.\n",
    "$$\\hat{\\theta} = (X^T X)^{-1}X^T Y$$\n",
    "\n",
    "Otra forma de hacer esta busqueda del minimo de RSS o funcion de costo en el lenguage de Machine Learning es utilizando una tecnica llamada Gradient Descent que es tipica en ML y que aparece explicado en el segundo item del curso Machine Learning de Andrew Ng."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "Y_train=[]\n",
    "\n",
    "#Los valores de SET[i][1] y SET[i][2] se colocarán en X y se vizualizarán como las nuevas variables x1 y x2.\n",
    "for i in range(len(SET_train)):  \n",
    "    X_train.append([1,SET_train[i][1],SET_train[i][2]])\n",
    "\n",
    "\n",
    "#Ahora se colocarán los valores SET[i][3] en Y.\n",
    "for i in range(len(SET_train)): \n",
    "    Y_train.append(SET_train[i][3])\n",
    "    \n",
    "X_train=np.array(X_train)                     \n",
    "Y_train=np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "Y_test=[]\n",
    "\n",
    "for i in range(len(SET_test)):  \n",
    "    X_test.append([1,SET_test[i][1],SET_test[i][2]])\n",
    "\n",
    "\n",
    "#Ahora se colocarán los valores SET[i][3] en Y.\n",
    "for i in range(len(SET_test)): \n",
    "    Y_test.append(SET_test[i][3])\n",
    "    \n",
    "X_test=np.array(X_test)                     \n",
    "Y_test=np.array(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_test.shape , Y_train.shape , Y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XT=X_train.transpose()\n",
    "XTdotX = np.dot(XT,X_train)\n",
    "XTdotX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTdotX_inversa = np.linalg.inv(XTdotX)\n",
    "XTdotX_inversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "XTdotX_inversa_dotXT = np.dot(XTdotX_inversa, XT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_analitico = np.dot(XTdotX_inversa_dotXT,Y_train)\n",
    "print(theta_analitico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Costo_lineal(theta,X,Y):    \n",
    "    m = len(X)\n",
    "    theta = np.array(theta)\n",
    "    Xtheta = np.dot(X, theta)\n",
    "    YXT =(Y-Xtheta).transpose()\n",
    "    YX = (Y-Xtheta)\n",
    "    RSS= 1/(2*m)*np.dot(YXT,YX) \n",
    "    return RSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Costo_lineal(theta_analitico,X_train,Y_train)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizacion de las predicciones considerando los datos del conjunto de testeo y del conjunto de entrenamiento\n",
    "\n",
    "Con el valor del vector theta_analitico es posible visualizar como funciona este modelo de prediccion con la función lineal para los puntos del conjunto de entrenamuiento y del conjunto de testeo separadamente.\n",
    "\n",
    "Para esto, primero se necesita crear las siguientes funciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def funcion_lineal(x1, x2, theta): \n",
    "    \n",
    "    y_prediccion = theta[0] + x1*theta[1] + x2*theta[2]\n",
    "    return y_prediccion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listas_de_predicciones_lineal(SET):\n",
    "\n",
    "    lista_de_predicciones_azul = []\n",
    "    lista_de_predicciones_rojo = []\n",
    "\n",
    "    for pto in range(len(SET)):\n",
    "        prediccion = funcion_lineal(SET[pto][1], SET[pto][2], theta_analitico)\n",
    "\n",
    "    #Utilizando el valor de la prediccion separamos entre puntos azules y rojos\n",
    "    \n",
    "        if (prediccion <= 0.5):\n",
    "            lista_de_predicciones_azul.append([SET[pto][1], SET[pto][2]])\n",
    "        if (prediccion > 0.5):\n",
    "            lista_de_predicciones_rojo.append([SET[pto][1], SET[pto][2]])\n",
    "        \n",
    "    return np.array(lista_de_predicciones_azul), np.array(lista_de_predicciones_rojo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para visualizar las predicciones hechas haremos lo siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_azul_train_lineal, prediccion_rojo_train_lineal = listas_de_predicciones_lineal(SET_train)\n",
    "\n",
    "prediccion_azul_train_lineal_t = prediccion_azul_train_lineal.transpose()\n",
    "prediccion_rojo_train_lineal_t = prediccion_rojo_train_lineal.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_azul_test_lineal, prediccion_rojo_test_lineal = listas_de_predicciones_lineal(SET_test)\n",
    "\n",
    "prediccion_azul_test_lineal_t = prediccion_azul_test_lineal.transpose()\n",
    "prediccion_rojo_test_lineal_t = prediccion_rojo_test_lineal.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto podemos comparar visualmente las predicciones sobre el conjunto de entrenamiento y el coonjunto de testeo. A continuación se observan los 200 puntos simulados inicialmente que pertenecen al conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(ptos_observados_azul_train, ptos_observados_rojo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se observa la predicción hecha por la función lineal en el conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(prediccion_azul_train_lineal_t, prediccion_rojo_train_lineal_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación observamos los 10000 puntos creados anteriormente que pertenecen al SET_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(ptos_observados_azul_test, ptos_observados_rojo_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se observa la predicción hecha por la función lineal para estos puntos pertenecientes a SET_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(prediccion_azul_test_lineal_t, prediccion_rojo_test_lineal_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de la hipotesis lineal en terminos de las metricas \"Accuracy\" y el \"Test Error\"\n",
    "\n",
    "Por definicion vamos a considerar que la accuracy y el test error estan dados por\n",
    "\n",
    "$$Accuracy = \\frac{PC}{PC+ PI}$$ \n",
    "Con PC los puntos predichos correctamente y PI los puntos predichos incorrectamente\n",
    "\n",
    "$$Test_{error} = 1 - accuracy$$\n",
    "\n",
    "Estas son métricas que nos permiten evaluar la performance de la hipótesis (en este caso la función lineal) una vez que hemos encontrado los valores de los parametros libres ($\\theta$). Evaluaremos estas dos métricas en ambos conjuntos de datos (el de entrenamiento y el de testeo).\n",
    "\n",
    "El valor del Accuracy (o la exactitud) medido en el conjunto de entrenamiento nos indica cuantitativamente el nivel de aprendizaje del modelo, dado que en este paso estamos intentando ajustar el modelo a los datos conocidos. Mientras que el Acurracy medido en el conjunto de testeo nos indica su poder de prediccion, dado que estos datos no fueron utilizados para el entrenamiento del modelo. \n",
    "\n",
    "Normalmente se espera que el valor de la Accuracy sea mejor (o más cercano a 1) en el conjunto de entrenamiento que en el conjunto de testeo, porque los datos del primer conjunto fueron los utilizados para calcular los parametros del modelo. Sin embargo esto no está garantizado matemáticamente.\n",
    "\n",
    "En general es recomendable obtener un valor del accuracy cercano a 1 en el conjunto de testeo dado que nuestro objectivo final es tener poder de prediccion, no solo de ajustar los datos conocidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_funcion_lineal(SET, theta):\n",
    "\n",
    "    ptos_correctos = 0\n",
    "    ptos_incorrectos = 0\n",
    "    \n",
    "    for pto in range(len(SET)):\n",
    "        prediccion = funcion_lineal(SET[pto][1], SET[pto][2], theta)\n",
    "        \n",
    "        if (((prediccion < 0.5) and (SET[pto][3]==0)) or\n",
    "            ((prediccion > 0.5) and (SET[pto][3]==1))):\n",
    "            \n",
    "            ptos_correctos = ptos_correctos + 1\n",
    "        else:\n",
    "            ptos_incorrectos = ptos_incorrectos + 1\n",
    "            \n",
    "    ratio = ptos_correctos/(ptos_correctos + ptos_incorrectos)\n",
    "        \n",
    "        \n",
    "    print(\"puntos correctos: %d y puntos incorrectos: %d\"%(ptos_correctos, ptos_incorrectos))\n",
    "        \n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo usando el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_lineal = accuracy_funcion_lineal(SET_train, theta_analitico)\n",
    "train_error_lineal = 1 - train_accuracy_lineal\n",
    "print(\"train accuracy lineal: %.2f and test error lineal: %.2f \"%(train_accuracy_lineal, train_error_lineal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo usando el conjunto de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_lineal = accuracy_funcion_lineal(SET_test, theta_analitico)\n",
    "test_error_lineal = 1 - test_accuracy_lineal\n",
    "print(\"test accuracy lineal: %.2f and test error lineal: %.2f \"%(test_accuracy_lineal, test_error_lineal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso 2: Función Sigmoid\n",
    "\n",
    "- Hipótesis 2: Función sigmoid ($\\sigma$)\n",
    "- Función de costo: $J(\\theta)$ regresión logística \n",
    "- Minimización: theta obtenido por gradient descent\n",
    "- Evaluación: accuracy y test error\n",
    "\n",
    "Para este caso asumimos que el modelo de clasificación o hipotesis esta dado por una funcion del tipo \n",
    "\n",
    "$$ h(x_1^{(i)},x_2^{(i)}) = \\sigma(\\theta_0 + \\theta_1 x_1^{(i)} + \\theta_2 x_2^{(i)})$$\n",
    "$$h(x_1^{(i)},x_2^{(i)}) = \\frac{1}{1+e^{-(\\theta_0 + \\theta_1 x_1^{(i)} + \\theta_2 x_2^{(i)})}}$$\n",
    "\n",
    "Los valores de $\\theta$ son obtenidos a partir de la busqueda del minimo de la funcion $J(\\theta)$ con respecto a los datos del conjunto de entrenamiento.\n",
    "\n",
    "$$ J(\\theta) = \\frac{-1}{m}\\sum_{i=1}^m (y^{(i)}\\log(h(x_1^{(i)},x_2^{(i)}))+(1-y^{(i)})\\log(1-h(x_1^{(i)},x_2^{(i)})))$$\n",
    "\n",
    "Este minimo puede ser encontrado analíticamente, aleatoriamente o con gradient descent. En este caso utilizaremos el método de gradient descent. Este método es un algoritmo de optimización que permite converger hacia el valor mínimo de la función de costo mediante un proceso iterativo.\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\alpha \\frac{\\partial J(\\theta)}{\\partial \\theta_j}$$\n",
    "\n",
    "En donde el símbolo $\":=\"$ significa que lo que aparece al costado izquierdo de la ecuación se actualizará en cada iteración con el valor obtenido en el costado derecho de esta. El índice de aprendizaje es representado por $\\alpha$, el cual indica el tamaño de los pasos que se darán en cada iteración y debe ser escogido estratégicamente. La implementación de este algoritmo se puede vectorizar como se muestra a continuación.\n",
    "\n",
    "$$ \\theta_j := \\theta_j - \\frac{\\alpha}{m}X^T (g(X \\theta)-y)) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, Y_train.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_inicial = [] \n",
    "for i in range(len(theta_analitico)):\n",
    "    np.random.seed(10)\n",
    "    a = np.random.uniform(theta_analitico[i] - 0.5 , theta_analitico[i] + 0.5) \n",
    "    theta_inicial.append(a)\n",
    "\n",
    "print(theta_analitico, theta_inicial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Sigmoid(v):\n",
    "    largo = len(v)\n",
    "    g=[]\n",
    "    \n",
    "    for i in range(largo):\n",
    "        g.append(1/(1+np.exp(-v[i])))\n",
    "    return np.array(g)\n",
    "\n",
    "\n",
    "\n",
    "def Costo_Sigmoid(X, y, theta):\n",
    "    Sum = 0\n",
    "    m = X.shape[0]\n",
    "    theta = np.array(theta)\n",
    "    \n",
    "    for i in range(m):\n",
    "        Xtheta = np.dot(X, theta)\n",
    "        Xtheta = np.array(Xtheta)\n",
    "        h = Sigmoid(Xtheta)\n",
    "        Sum = Sum + ((y[i]*np.log(h[i])) + (1 - y[i])*np.log(1 - h[i]))\n",
    "        \n",
    "    return -(Sum/m)\n",
    "\n",
    "\n",
    "\n",
    "def Gradient_Descent(theta,X,y,alpha, iteraciones):\n",
    "    X=np.array(X)\n",
    "    XT=X.transpose()\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    lista_J=[]\n",
    "    lista_iteracion = []\n",
    "    \n",
    "    for i in range(iteraciones):\n",
    "        \n",
    "        Xtheta = np.dot(X, theta)\n",
    "        resta = Sigmoid(Xtheta)-y\n",
    "        XTSigmoid = np.dot(XT,resta)\n",
    "        \n",
    "        theta = theta - (alpha/m) * XTSigmoid\n",
    "        \n",
    "        J = Costo_Sigmoid(X, y, theta) \n",
    "        \n",
    "        lista_J.append(J)\n",
    "        lista_iteracion.append(i)\n",
    "    \n",
    "    return np.array(lista_J) , np.array(lista_iteracion),theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probemos con valores de $\\alpha$ chicos y 50 iteraciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_1,iteraciones_1,theta_1 = Gradient_Descent(theta_inicial,X_train,Y_train,0.01,50)\n",
    "J_2,iteraciones_2,theta_2 = Gradient_Descent(theta_inicial,X_train,Y_train,0.1,50)\n",
    "J_3,iteraciones_3,theta_3 = Gradient_Descent(theta_inicial,X_train,Y_train,1,50)\n",
    "J_4,iteraciones_4,theta_4 = Gradient_Descent(theta_inicial,X_train,Y_train,5,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iteraciones_1,J_1,\"ro\", label=\"alpha=0.01\")\n",
    "plt.plot(iteraciones_2,J_2,\"bo\",label=\"alpha=0.1\")\n",
    "plt.plot(iteraciones_3,J_3,\"co\",label=\"alpha=1\")\n",
    "plt.plot(iteraciones_4,J_4,\"yo\",label=\"alpha=5\")\n",
    "\n",
    "plt.title(\"Evolución función de costo\")\n",
    "plt.legend(loc='center right')\n",
    "plt.ylabel(\"Costo\")\n",
    "plt.xlabel(\"Iteraciones\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que con  𝛼=1  la función de costo pudo converger rápidamente a un valor estable y cercano al mínimo. Con 50 iteraciones y con  𝛼=1 , la función de costo vale 0.4174683. Ahora veamos que sucede con valores de $\\alpha$ más grandes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_5,iteraciones_5,theta_5 = Gradient_Descent(theta_inicial,X_train,Y_train,5,20)\n",
    "J_6,iteraciones_6,theta_6 = Gradient_Descent(theta_inicial,X_train,Y_train,10,20)\n",
    "J_7,iteraciones_7,theta_7 = Gradient_Descent(theta_inicial,X_train,Y_train,15,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(iteraciones_5,J_5,\"yo\", label=\"alpha=5\")\n",
    "plt.plot(iteraciones_6,J_6,\"go\",label=\"alpha=10\")\n",
    "plt.plot(iteraciones_7,J_7,\"mo\",label=\"alpha=15\")\n",
    "plt.legend(loc='center right')\n",
    "plt.title(\"Evolución función de costo\")\n",
    "plt.ylabel(\"Costo\")\n",
    "plt.xlabel(\"Iteraciones\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver este notebook me quedaré con $\\alpha = 7$ y con 20 iteraciones, ya que con estas variables la función de costo presenta un comportamiento estable y un valor muy pequeño. Con 20 iteraciones y con $\\alpha=7$, el menor valor de la función de costo es 0.33182636 y el theta correspondiente se muestra a continuación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_4[49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def listas_de_predicciones_sigmoid(SET,theta):\n",
    "\n",
    "    lista_predicciones_azul = []\n",
    "    lista_predicciones_rojo = []\n",
    "    \n",
    "    X = []\n",
    "    for i in range(len(SET)):  \n",
    "        X.append([1,SET[i][1],SET[i][2]])\n",
    "    \n",
    "    Xtheta = np.dot(X,theta)\n",
    "    \n",
    "    prediccion = Sigmoid(Xtheta)\n",
    "    \n",
    "    for pto in range(len(SET)):\n",
    "    \n",
    "        if (prediccion[pto] <= 0.5):\n",
    "            lista_predicciones_azul.append([SET[pto][1], SET[pto][2]])\n",
    "        if (prediccion[pto] > 0.5):\n",
    "            lista_predicciones_rojo.append([SET[pto][1], SET[pto][2]])\n",
    "        \n",
    "    return np.array(lista_predicciones_azul), np.array(lista_predicciones_rojo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_azul_train_sigmoid, prediccion_rojo_train_sigmoid = listas_de_predicciones_sigmoid(SET_train,theta_4)\n",
    "\n",
    "prediccion_azul_train_sigmoid_t = prediccion_azul_train_sigmoid.transpose()\n",
    "prediccion_rojo_train_sigmoid_t = prediccion_rojo_train_sigmoid.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_azul_test_sigmoid, prediccion_rojo_test_sigmoid = listas_de_predicciones_sigmoid(SET_test,theta_4)\n",
    "\n",
    "prediccion_azul_test_sigmoid_t = prediccion_azul_test_sigmoid.transpose()\n",
    "prediccion_rojo_test_sigmoid_t = prediccion_rojo_test_sigmoid.transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esto podemos comparar visualmente las predicciones sobre el conjunto de entrenamiento y el conjunto de testeo, utilizando un modelo predictivo con la función sigmoid. A continuación se observan los 200 puntos simulados inicialmente que pertenecen al conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(ptos_observados_azul_train, ptos_observados_rojo_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se observa la predicción hecha por la función sigmoid en el conjunto de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(prediccion_azul_train_sigmoid_t, prediccion_rojo_train_sigmoid_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación observamos los 10000 puntos creados anteriormente que pertenecen al SET_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(ptos_observados_azul_test, ptos_observados_rojo_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se observa la predicción hecha por la función sigmoid para estos puntos pertenecientes a SET_test:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(prediccion_azul_test_sigmoid_t, prediccion_rojo_test_sigmoid_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación de la hipotesis sigmoid en terminos de las metricas \"Accuracy\" y el \"Test Error\"\n",
    "\n",
    "Recordemos que:\n",
    "\n",
    "$$Accuracy = \\frac{PC}{PC+ PI}$$ \n",
    "Con PC los puntos predichos correctamente y PI los puntos predichos incorrectamente\n",
    "\n",
    "$$Test_{error} = 1 - accuracy$$\n",
    "\n",
    "Con estas métricas evaluaremos la performance de la hipótesis de la función sigmoid. Evaluaremos estas dos métricas en ambos conjuntos de datos (el de entrenamiento y el de testeo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_funcion_sigmoid(SET, theta):\n",
    "\n",
    "    ptos_correctos = 0\n",
    "    ptos_incorrectos = 0\n",
    "    \n",
    "    X = []\n",
    "    for i in range(len(SET)):  \n",
    "        X.append([1,SET[i][1],SET[i][2]])\n",
    "    \n",
    "    Xtheta = np.dot(X,theta)\n",
    "    \n",
    "    prediccion = Sigmoid(Xtheta)\n",
    "    \n",
    "    for pto in range(len(SET)):\n",
    "        \n",
    "        if (((prediccion[pto] <= 0.5) and (SET[pto][3]==0)) or\n",
    "            ((prediccion[pto] > 0.5) and (SET[pto][3]==1))):\n",
    "            \n",
    "            ptos_correctos = ptos_correctos + 1\n",
    "        else:\n",
    "            ptos_incorrectos = ptos_incorrectos + 1\n",
    "            \n",
    "    ratio = ptos_correctos/(ptos_correctos + ptos_incorrectos)\n",
    "        \n",
    "        \n",
    "    print(\"puntos correctos: %d y puntos incorrectos: %d\"%(ptos_correctos, ptos_incorrectos))\n",
    "        \n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo usando el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_sigmoid = accuracy_funcion_sigmoid(SET_train, theta_4)\n",
    "train_error_sigmoid = 1 - train_accuracy_sigmoid\n",
    "print(\"train accuracy sigmoid: %.2f and test error sigmoid: %.2f \"%(train_accuracy_sigmoid, train_error_sigmoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo usando el conjunto de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_accuracy_sigmoid = accuracy_funcion_sigmoid(SET_test, theta_4)\n",
    "test_error_sigmoid = 1 - test_accuracy_sigmoid\n",
    "print(\"test accuracy sigmoid: %.2f and test error sigmoid: %.2f \"%(test_accuracy_sigmoid, test_error_sigmoid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Caso 3: Redes Neuronales\n",
    "\n",
    "- Hipótesis: Función sigmoid ($\\sigma$)\n",
    "- Función de costo: binary_crossentropy\n",
    "- Minimización: backpropagation\n",
    "- Evaluación: accuracy \n",
    "\n",
    "Añadiremos una capa a la vez, las que seguirán las siguientes características:\n",
    "\n",
    "El modelo esperará filas de los datos con 2 variables, por lo que el argumento input_dim=2.\n",
    "La primera capa oculta tendrá 2 nodos o neuronas (al parecer el bias no se considera), lo que obtenemos al escribir un 2 en la primera variable de entrada de Dense y tendrá una función de activación sigmoid, ya que de esta forma lo resolvimos en el resumen.\n",
    "La capa de salida tendrá solo una neurona y también usará una función de activación sigmoid.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definición del modelo utilizando Keras\n",
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=2, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilación del modelo:\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualización de la red neuronal\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ajustar el modelo al conjunto de datos de entrenamiento (con esto se aprenden los wights)\n",
    "#no debemos considerar el bias, por eso ponemos X_train[:,1:]\n",
    "\n",
    "model.fit(X_train[:,1:], Y_train, epochs=150, batch_size=50)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluación del modelo usando el conjunto de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_train, accuracy_train = model.evaluate(X_train[:,1:], Y_train)\n",
    "print('Accuracy train: %.2f' % (accuracy_train*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluación del modelo usando el conjunto de testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluación del modelo para el conjunto de testeo\n",
    "J_test, accuracy_test = model.evaluate(X_test[:,1:], Y_test)\n",
    "print('Accuracy test: %.2f' % (accuracy_test*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion_train = model.predict(X_train[:,1:]) #sin aproximar\n",
    "prediccion_final_train = [round(x[0]) for x in prediccion_train] #aproxima a 1 o a 0\n",
    "\n",
    "\n",
    "prediccion_test = model.predict(X_test[:,1:]) #sin aproximar\n",
    "prediccion_final_test = [round(x[0]) for x in prediccion_test] #aproxima a 1 o a 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puntos_azul_train = []\n",
    "puntos_rojo_train = []\n",
    "\n",
    "for i in range(len(prediccion_final_train)):\n",
    "    if prediccion_final_train[i] == 1:\n",
    "        puntos_rojo_train.append(X_train[i,1:])\n",
    "    else:\n",
    "        puntos_azul_train.append(X_train[i,1:])\n",
    "        \n",
    "puntos_azul_test = []\n",
    "puntos_rojo_test = []\n",
    "\n",
    "for i in range(len(prediccion_final_test)):\n",
    "    if prediccion_final_test[i] == 1:\n",
    "        puntos_rojo_test.append(X_test[i,1:])\n",
    "    else:\n",
    "        puntos_azul_test.append(X_test[i,1:])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "puntos_azul_train_t = np.array(puntos_azul_train).transpose()\n",
    "puntos_rojo_train_t = np.array(puntos_rojo_train).transpose()\n",
    "\n",
    "puntos_azul_test_t = np.array(puntos_azul_test).transpose()\n",
    "puntos_rojo_test_t = np.array(puntos_rojo_test).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_colors(ptos_azul, ptos_rojo):\n",
    "\n",
    "    x1azul = ptos_azul[0]\n",
    "    x2azul = ptos_azul[1]\n",
    "    \n",
    "    x1rojo = ptos_rojo[0]\n",
    "    x2rojo = ptos_rojo[1]\n",
    "    \n",
    "    plt.plot(x1azul,x2azul,\"bo\")\n",
    "    plt.plot(x1rojo,x2rojo,\"ro\")\n",
    "    plt.axis([-4,4,-4,4])\n",
    "    plt.title(\"Distribucion de puntos segun el color\")\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(puntos_azul_train_t, puntos_rojo_train_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_colors(puntos_azul_test_t, puntos_rojo_test_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparando el valor del Acurracy obtenido para los tres modelos analizados, podemos notar que estos presentan un valor de Acurracy bastante similar. Esto muestra la consistencia del método gradient descent para encontrar los parámetros libres de J($\\theta$), ya que obtuvo el mismo error que se calculó anteriormente de manera analítica para la hipótesis lineal. Para aumentar la presición de la red neuronal se podrían utilizar más neuronas en la capa oculta o agregar más capas ocultas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
